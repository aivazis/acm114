% -*- LaTeX -*-
% -*- coding: utf-8 -*-
%
% michael a.g. aïvázis
% california institute of technology
% (c) 1998-2012 all rights reserved
%

\lecture{Wrapping up the shared memory implementation}{20120227}

% --------------------------------------
% required changes to the sequential driver
\begin{frame}[fragile]
%
  \frametitle{Required changes to the sequential solution}
%
  \begin{itemize}
%
  \item what is needed
    \begin{itemize}
    \item an object to hold the problem information shared among the threads
    \item the per-thread administrative data structure that holds the thread id and the pointer
      to the shared information
      \begin{itemize}
      \item this is the argument to \function{pthread\_create}
      \end{itemize}
    \item a mutex to protect the update of the global convergence criterion
    \item a \function{pthread\_create} compatible worker routine
    \item a change at the top-level driver to enable the user to choose the number of threads
    \end{itemize}
%
  \item and a strategy for managing the thread life cycle
    \begin{itemize}
%
    \item synchronization is trivial if
      \begin{itemize}
      \item we spawn our threads to perform the updates of a single iteration
      \item harvest them
      \item check the convergence criterion 
      \item stop, or respawn them if another iteration is necessary
      \end{itemize}
%
    \item can the convergence test be done in parallel?
      \begin{itemize}
        \item so we don't have to pay the create/harvest overhead?
        \item if so, how do we guarantee correctness and consistency?
      \end{itemize}
%
    \end{itemize}
% 
  \end{itemize}
%
\end{frame}

% --------------------------------------
% the jacobi solver 
\begin{frame}[fragile]
% 
  \frametitle{Threaded \class{Jacobi}: thread data}
%
  \begin{lstlisting}[language=c++,name=Jacobi:threaded]
struct Task {
    // shared information 
    size_t workers;
    Grid & current;
    Grid & next;
    double maxDeviation;
    // mutex to control access to the convergence criterion
    pthread_mutex_t lock; 

    // constructor
    Task(size_t workers, Grid & current, Grid & next) :
        workers(workers), current(current), next(next), maxDeviation(0.0) {
        pthread_mutex_init(&lock, 0);
    }
    // destructor
    ~Task() {
        pthread_mutex_destroy(&lock);
    }
};

struct Context {
    // thread info
    size_t id;
    pthread_t descriptor;
    Task * task;
};

  \end{lstlisting}
%
\end{frame}

% --------------------------------------
% the jacobi solver 
\begin{frame}[fragile]
% 
  \frametitle{Threaded \class{Jacobi}: driving the update}
%
  \begin{lstlisting}[language=c++,name=Jacobi:threaded]
void Jacobi::solve(Problem & problem) {
    // initialize the problem
    problem.initialize();
    // do the actual solve
    _solve(problem);
    // compute and store the error
    std::cout << "  computing absolute error" << std::endl;
    //  compute the relative error
    Grid & error = problem.error();
    const Grid & exact = problem.exact();
    const Grid & solution = problem.solution();

    for (size_t j=0; j < exact.size(); j++) {
        for (size_t i=0; i < exact.size(); i++) {
            if (exact(i,j) == 0.0) {
                error(i,j) = std::abs(solution(i,j));
            } else {
                error(i,j) = std::abs(solution(i,j) - exact(i,j))/exact(i,j);
            }
        }
    }
    std::cout << " --- done." << std::endl;
    return;
}
  \end{lstlisting}
%
\end{frame}

% --------------------------------------
% the jacobi solver 
\begin{frame}[fragile]
% 
  \frametitle{Threaded \class{Jacobi}: the master thread}
%
  \begin{lstlisting}[language=c++,name=Jacobi:threaded]
void Jacobi::_solve(Problem & problem) {
    Grid & current = problem.solution();

    // create and initialize temporary storage
    Grid next(current.size());
    problem.initialize(next);

    // shared thread info
    Task task(_workers, current, next);
    // per-thread information
    Context context[_workers];

    // let's get going
    std::cout << "jacobi: tolerance=" << _tolerance << std::endl;

    // put an upper bound on the number of iterations
    const size_t max_iterations = (size_t) 1.0e4;
  \end{lstlisting}
%
\end{frame}

% --------------------------------------
% the jacobi solver 
\begin{frame}[fragile]
% 
  \frametitle{Threaded \class{Jacobi}: the master thread, part 2}
%
  \begin{lstlisting}[language=c++,name=Jacobi:threaded,basicstyle=\tt\bfseries\tiny]
    for (size_t iterations = 0; iterations<max_iterations; iterations++) {
        if (iterations % 100 == 0) {
            std::cout << "     " << iterations << std::endl;
        }
        // reset the maximium deviation
        task.maxDeviation = 0.0;
        // spawn the threads
        for (size_t tid=0; tid < _workers; tid++) {
            context[tid].id = tid;
            context[tid].task = &task;

            int status = pthread_create(&context[tid].descriptor, 0, _update, &context[tid]);
            if (status) {
                throw ("error in pthread_create");
            }
        }
        // harvest the threads
        for (size_t tid = 0; tid < _workers; tid++) {
            pthread_join(context[tid].descriptor, 0);
        }

        // swap the blocks between the two grids
        Grid::swapBlocks(current, next);
        // check covergence
        if (task.maxDeviation < _tolerance) {
            std::cout << " ### convergence in " << iterations << " iterations!" << std::endl;
            break;
        }
    }
    std::cout << " --- done." << std::endl;

    return;
}
  \end{lstlisting}
%
\end{frame}

% --------------------------------------
% the jacobi solver 
\begin{frame}[fragile]
% 
  \frametitle{Threaded \class{Jacobi}: update in the worker threads}
%
  \begin{lstlisting}[language=c++,basicstyle=\tt\bfseries\tiny,name=Jacobi:threaded]
void * Jacobi::_update(void * arg) {
    Context * context = static_cast<Context *>(arg);

    size_t id = context->id;
    Task * task = context->task;

    size_t workers = task->workers;
    Grid & current = task->current;
    Grid & next = task->next;
    pthread_mutex_t lock = task->lock;

    double max_dev = 0.0;
    // do an iteration step
    // leave the boundary alone
    // iterate over the interior of the grid
    for (size_t j=id+1; j < current.size()-1; j+=workers) {
        for (size_t i=1; i < current.size()-1; i++) {
            next(i,j) = 0.25*(current(i+1,j)+current(i-1,j)+current(i,j+1)+current(i,j-1));
            // compute the deviation from the last generation
            double dev = std::abs(next(i,j) - current(i,j));
            // and update the maximum deviation
            if (dev > max_dev) {
                max_dev = dev;
            }
        }
    }

    // grab the lock and update the global maximum deviation
    pthread_mutex_lock(&lock);
    if (task->maxDeviation < max_dev) {
        task->maxDeviation = max_dev;
    }
    pthread_mutex_unlock(&lock);

    return 0;
}
  \end{lstlisting}
%
\end{frame}

% --------------------------------------
% improving the threaded implementation
\begin{frame}[fragile]
%
  \frametitle{Assessing the threaded implementation}
%
  \begin{itemize}
%
  \item the implemented synchronization scheme is very simple
    \begin{itemize}
    \item each grid update step spawns some number of workers to update a subset of the cells
    \item the workers are harvested after the grid is updated
    \item the main thread checks for convergence
    \item if another iteration is required, a new set of workers is spawned
    \end{itemize}
%
  \item the simplicity of this strategy comes at a cost
    \begin{itemize}
    \item {\em scalability} suffers when the overhead of creating and harvesting threads is
      comparable to amount of work done by each thread
    \item for low thread counts, it is still an overall win, since the time to solution
      decreases and the machine utilization is better
    \item but as the number of threads increases, the program becomes {\em slower}
      \begin{itemize}
      \item timing a $100\times100$ grid to convergence on a recent MacPro
%
        \begin{equation*}
          \begin{array}{r|ccccc}
% header
            {\rm threads } & 1 & 2 & 4 & 8 & 16 \\
            \hline 
            {\rm time} (s) & 4.367 & 2.517 & 1.918 & 1.937 & 3.537
% 
          \end{array}
        \end{equation*}
      \item and 10,000 iterations of a $1000\times1000$ grid
        \begin{equation*}
          \begin{array}{r|ccccc}
% header
            {\rm threads } & 1 & 2 & 4 & 8 & 16 \\
            \hline 
            {\rm time} (s) & 413.306 & 211.050 & 109.509 & 98.279 & 74.087
% 
          \end{array}
        \end{equation*}
      \end{itemize}

    \end{itemize}
%
\end{itemize}
%
\end{frame}

% --------------------------------------
% Improving the update loop
\begin{frame}[fragile]
%
  \frametitle{Improving the update loop}
%
  \begin{itemize}
%
  \item the plan is to keep the workers alive and updating the grid while either we converge or
    \identifier{max\_iterations} is reached
  \item the main thread
    \begin{itemize}
    \item loops to spawn all the threads
    \item and immediately enters a loop to harvest them
    \end{itemize}
%
  \item the workers use a condition variable to synchronize among themselves
    \begin{itemize}
    \item they iterate, updating the grid
    \item grab a mutex, deposit their local maximum deviation from the last iterations, update
      a counter that records how many workers have completed their update, and release the lock
    \item enter another critical section with the termination logic
      \begin{itemize}
      \item everybody uses a condition variable to wait for the slowest worker
      \item the slowest worker checks the convergence criterion and updates the termination
        flag, swaps the grid blocks and signals everybody else
      \item if the termination flag is set, or if the maximum number of iterations has been
        reached, all threads exit
      \end{itemize}
    \end{itemize}
%
  \end{itemize}
%
\end{frame}

% --------------------------------------
% the jacobi solver 
\begin{frame}[fragile]
% 
  \frametitle{Threaded \class{Jacobi}: the main thread}
%
  \begin{lstlisting}[language=c++,name=Jacobi:updated-solve,basicstyle=\tt\bfseries\tiny]
void Jacobi::_solve(Problem & problem) {
    Grid & current = problem.solution();

    // create and initialize temporary storage
    Grid next(current.size());
    problem.initialize(next);

    // shared thread info
    Task task(_workers, _tolerance, current, next);
    // per-thread information
    Context context[_workers];
    // spawn the threads
    std::cout << "jacobi: spawning " << _workers << " workers" << std::endl;
    for (size_t tid=0; tid < _workers; tid++) {
        context[tid].id = tid;
        context[tid].task = &task;
        
        int status = pthread_create(&context[tid].descriptor, 0, _update, &context[tid]);
        if (status) {
            throw ("error in pthread_create");
        }
    }
    // harvest the threads
    for (size_t tid = 0; tid < _workers; tid++) {
            pthread_join(context[tid].descriptor, 0);
        }
    // done
    std::cout << "jacobi: done." << std::endl;
    return;
}
  \end{lstlisting}
%
\end{frame}

% --------------------------------------
% the jacobi solver 
\begin{frame}[fragile]
% 
  \frametitle{Threaded \class{Jacobi}: updated thread data}
%
  \begin{lstlisting}[language=c++,name=Jacobi:updated-threaded,basicstyle=\tt\bfseries\tiny]
struct Task {
    // shared information 
    size_t workers; // the number of threads
    double tolerance; // the covergence tolerance
    Grid & current;
    Grid & next;

    bool done; // is there more work?
    double maxDeviation; // the value
    size_t contributions; // the number of threads that have deposited contributions
    pthread_mutex_t gridUpdate_lock; //the mutex
    pthread_cond_t gridUpdate_check;

    Task(size_t workers, double tolerance, Grid & current, Grid & next) :
        workers(workers), tolerance(tolerance), current(current), next(next),
        done(false), maxDeviation(0.0), contributions(0),
        gridUpdate_lock(), gridUpdate_check() {
        // initialize the grid update lock
        pthread_mutex_init(&gridUpdate_lock, 0);
        pthread_cond_init(&gridUpdate_check, 0);
    }

    ~Task() {
        pthread_mutex_destroy(&gridUpdate_lock);
        pthread_cond_destroy(&gridUpdate_check);
    }
};

  \end{lstlisting}
%
\end{frame}

% --------------------------------------
% the jacobi solver 
\begin{frame}[fragile]
% 
  \frametitle{Threaded \class{Jacobi}: workers, part 1}
%
  \begin{lstlisting}[language=c++,name=Jacobi:updated-solve,basicstyle=\tt\bfseries\tiny]
// the threaded update
void * Jacobi::_update(void * arg) {
    Context * context = static_cast<Context *>(arg);

    size_t id = context->id;
    Task * task = context->task;

    const size_t workers = task->workers;
    Grid & current = task->current;
    Grid & next = task->next;

    size_t maxIterations = (size_t) 1e4;
    // iterate, updating the grid until done
    for (size_t iteration = 0; iteration < maxIterations; iteration++) {
        // thread 0: print an update
        if (id == 0 && iteration % 100 == 0) {
            std::cout << "    " << iteration << std::endl;
        }

        double max_dev = 0.0;
        // do an iteration step
        // leave the boundary alone
        // iterate over the interior of the grid
        for (size_t j=id+1; j < current.size()-1; j+=workers) {
            for (size_t i=1; i < current.size()-1; i++) {
                next(i,j) = 0.25*(current(i+1,j)+current(i-1,j)+current(i,j+1)+current(i,j-1));
                // compute the deviation from the last generation
                double dev = std::abs(next(i,j) - current(i,j));
                // and update the maximum deviation
                if (dev > max_dev) {
                    max_dev = dev;
                }
            }
        }
        // done with the grid update
  \end{lstlisting}
%
\end{frame}

% --------------------------------------
% the jacobi solver 
\begin{frame}[fragile]
% 
  \frametitle{Threaded \class{Jacobi}: workers, part 2}
%
  \begin{lstlisting}[language=c++,name=Jacobi:updated-solve,basicstyle=\tt\bfseries\tiny]
        // grab the grid update lock
        pthread_mutex_lock(&task->gridUpdate_lock);
        // update the global maximum deviation 
        if (task->maxDeviation < max_dev) {
            task->maxDeviation = max_dev;
        }
        // leave a mark
        task->contributions++;
        // bookkeeping at the end of the  update
        if (task->contributions == workers) {
            // if i am the slowest worker
            // swap the blocks between the two grids
            Grid::swapBlocks(current, next);
            // check covergence
            if (task->maxDeviation < task->tolerance) {
                std::cout
                    << " +++ thread " << id << ": convergence in " << iteration << " iterations"
                    <<std::endl;
                task->done = true;
            }
            // reset our accounting and signal everybody
            task->contributions = 0;
            task->maxDeviation = 0;
            pthread_cond_broadcast(&task->gridUpdate_check);
        } else {
            // all but the slowest wait here
            pthread_cond_wait(&task->gridUpdate_check, &task->gridUpdate_lock);
        } 
        // release
        pthread_mutex_unlock(&task->gridUpdate_lock);
        // check whether we are done
        if (task->done) {
            break;
        }
    }
    return 0;
}
  \end{lstlisting}
%
\end{frame}

% --------------------------------------
% improving the threaded implementation
\begin{frame}[fragile]
%
  \frametitle{Assessing the improved implementation}
%
  \begin{itemize}
%
  \item the improved threading scheme is not much more complex
    \begin{itemize}
    \item we keep track of how many threads have computed their grid update
    \item the slowest worker check the convergence criterion and performs all the necessary
      bookkeeping 
    \item while everybody else waits
    \item use \function{pthread\_cond\_brodacast} to wake the other workers
    \end{itemize}
%
  \item here is the performance comparison for 10,000 iterations on a $1000 \times 1000$ grid
    on the same 8-core MacPro
    \begin{equation*}
      \begin{array}{r|ccccc}
% header
        {\rm threads } & 1 & 2 & 4 & 8 & 16 \\
        \hline 
        {\rm previous} (s) & 413.306 & 211.050 & 109.509 & 98.279 & 74.087 \\
        {\rm updated} (s)  & 408.636 & 208.832 & 107.015 & 59.043 & 61.481 \\
% 
      \end{array}
    \end{equation*}
%
  \end{itemize}
%
\end{frame}

% end of file 
