% -*- LaTeX -*-
% -*- coding: utf-8 -*-
%
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%
%                             michael a.g. aïvázis
%                      california institute of technology
%                      (c) 1998-2010  all rights reserved
%
% ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%

\lecture{Overview of parallel systems}{20100108}

% --------------------------------------
% motivation for parallel computing
\begin{frame}[fragile]
%
  \frametitle{Motivations for going parallel}
%
  \begin{itemize}
%
  \item why bother?
    \begin{itemize}
    \item {\em speed}: there are fundamental limits to the processing power of a single processor
    \item {\em throughput}: time to solution is critical for many problems
    \item {\em size}: high resolution requires lots of memory
    \item {\em availability}: the tool exists, use it
    \end{itemize}
%
  \item but, be careful
    \begin{itemize}
    \item the commercial market is unstable
    \item the computing environment is somewhat primitive
    \item software packages and libraries are emerging slowly
    \item parallel programming is not hard, but it requires {\em discipline}
    \end{itemize}
%
  \end{itemize}
%
\end{frame}

% --------------------------------------
% computer system taxonomy
\begin{frame}[fragile]
%
  \frametitle{Taxonomy}
%
  \begin{itemize}
%
  \item an early classification of computer systems focused on the relation between {\em
    instruction streams} and {\em data streams}:
    \begin{itemize}
      \item SISD: single instruction, single data
      \item: SIMD: single instruction, multiple data
      \item: MIMD: multiple instruction, multiple data
    \end{itemize}
%
    \item SISD describes conventional serial computers
    \begin{itemize}
      \item the programming model; the hardware has moved on...
    \end{itemize}
%
    \item SIMD and MIMD are the traditional models for parallel machines
%
    \item MIMD systems are often programmed in SPMD mode: single {\em program}, multiple data
  \end{itemize}
%
\end{frame}

% --------------------------------------
% architectural issues
\begin{frame}[fragile]
%
  \frametitle{Architectural issues}
%
  \begin{itemize}
%
  \item {\em control:} SIMD vs.~MIMD
  \item {\em co\"ordination}: synchronous vs.~asynchronous
  \item {\em memory organization}: private vs.~shared
  \item {\em address space}: local vs.~global
  \item {\em memory access}: uniform vs.~ non-uniform
  \item {\em granularity}: the power of each processor
  \item {\em scalability}: dependence on the number of processors
  \item {\em interconnect}: topology, routing, switching
%
  \end{itemize}
%
\end{frame}

% --------------------------------------
% tradeoffs
\begin{frame}[fragile]
%
  \frametitle{Tradeoffs}
%
  \begin{center}
    \begin{minipage}{.75\linewidth}
      \begin{tabular}{l|l|l}
                        & shared memory & distributed memory \\ \hline
        scalability     & {\em harder}  & {\em easier} \\
        programmability & {\em easier}  & {\em harder}
      \end{tabular}
    \end{minipage}
  \end{center}

%
  \begin{itemize}
%
  \item shared memory permits parallelizing serial program gradually, focusing on worst
    bottlenecks first
%
  \item distributed memory requires partitioning and distributing both data and work across
    processors, which usually rules out incremental parallelization
%
  \end{itemize}
%
\end{frame}

% --------------------------------------
% categories of parallel architectures
\begin{frame}[fragile]
%
  \frametitle{Categories of parallel architectures}
%
  \begin{itemize}
%
  \item vector or array processor
  \item SMP: symmetric multiprocessor
  \item MPP: massively parallel multiprocessor
  \item DSM: distributed shared memory
  \item clusters
  \item hybrids
    \begin{itemize}
      \item SMP or MPP with vector processors
      \item networked clusters of SMPs
      \item SMP+GPGPU 
    \end{itemize}
%
  \end{itemize}
%
\end{frame}

% --------------------------------------
% memory hierarchy
\begin{frame}[fragile]
%
  \frametitle{Memory hierarchy}
%
  \begin{itemize}
  \item High performance architectures have a multi-tier memory hierarchy
%
    \begin{itemize}
%
    \item registers
    \item on-chip caches, usually referred to as level 1
    \item off-chip caches (level 2)
    \item random access memory
    \item remote memory (off processor)
    \item virtual memory, known as paging memory, that usually involves secondary storage
    \item secondary storage (disks)
    \item tertiary storage (tapes)
%
    \end{itemize}
%
  \end{itemize}
%
\end{frame}

% --------------------------------------
% parallel programming paradigms
\begin{frame}[fragile]
%
  \frametitle{Parallel programming paradigms}
%
  \begin{itemize}
%
  \item {\em functional languages}: specify what to compute, not how
  \item {\em parallelizing compilers}: automatic or semi-automatic detection of parallelism in
    serial code; mostly loop-unrolling, often with the help of special mark up (pragmas)
  \item {\em object oriented}: parallelism encapsulated within distributed objects

  \item {\em data parallel}: simultaneous operations on memory; mostly arrays
  \item {\em shared memory}: multiple threads executing a pool of tasks using common memory
  \item {\em remote memory access}: one sided put/get communication between processes
  \item {\em message passing}: two sided, co\"ordinated send/receive communication between
    processes
%
  \end{itemize}
%
\end{frame}

% --------------------------------------
% template
\begin{frame}[fragile]
%
  \frametitle{Blank}
%
  \begin{itemize}
%
  \item a point
%
  \end{itemize}
%
\end{frame}

% end of file 
